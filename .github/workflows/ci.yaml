name: CI Test Suite

on:
  push:
    branches:
      - main
      - ci/106-final
      - ci/106-fix-flag
      - ci/106-fix-flag2
      - ci/106-final-pass
      - ci/106-fix-3
      - ci/106-fix-4
      - ci/106-final-green
      - fix/fixtures-519-final4
  pull_request:
    branches:
      - main
  workflow_dispatch:

jobs:
  test:
    name: Test Suite (106 tests)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        working-directory: ./
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-json-report

      - name: Auth
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: "projects/1042559846495/locations/global/workloadIdentityPools/github-test-pool/providers/github-test-provider"
          service_account: "gemini-service-account@github-chatgpt-ggcloud.iam.gserviceaccount.com"

      - name: Setup gcloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Verify authentication
        working-directory: ./
        run: gcloud auth list

      - name: Assert Collection Count = 106
        working-directory: ./
        run: |
          echo "Checking test collection count with manifest filtering..."
          export CI=true
          # Let conftest.py handle the validation - it exits if not 106 tests
          pytest --collect-only -q > /dev/null
          echo "✅ SUCCESS: Conftest.py validated exactly 106 tests"

      - name: Run full test suite
        working-directory: ./
        run: |
          echo "Running full test suite with 106 tests..."
          export CI=true
          python -m pytest -v --json-report --json-report-file=.report.json

      - name: Validate Results
        working-directory: ./
        run: |
          echo "Validating test results..."
          python - <<'PY'
          import json, sys
          try:
            with open('.report.json', 'r') as f:
              report = json.load(f)
            
            total = report['summary']['total']
            failed = report['summary']['failed'] 
            skipped = report['summary']['skipped']
            passed = report['summary']['passed']
            
            print(f"Test Results: {passed} passed, {failed} failed, {skipped} skipped, {total} total")
            
            # Validate total count is 106
            if total != 106:
              print(f"ERROR: Expected 106 total tests, got {total}")
              sys.exit(1)
            
            # Fail if any test failed
            if failed > 0:
              print(f"ERROR: {failed} tests failed")
              sys.exit(1)
              
            # Warn if too many skipped (allow up to 6)
            if skipped > 6:
              print(f"ERROR: Too many tests skipped ({skipped} > 6)")
              sys.exit(1)
              
            print("✅ All validations passed!")
          except Exception as e:
            print(f"ERROR reading test report: {e}")
            sys.exit(1)
          PY

      - name: Upload test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-report-106
          path: .report.json